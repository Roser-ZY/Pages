---
title: "内存分页"
author: "Roser"
date: 2025-04-14
image: "images/content/OS.png"
draft: false
tags:
  - OS
  - Review
  - Draft
sr-due: 2025-05-15
sr-interval: 31
sr-ease: 250
---
内存分页（Paging)能够解决[[内存分段]]时外部内存碎片和内存交换效率问题。内存分页是指把整个虚拟和物理内存切成多个固定尺寸的内存页（Page）。

虚拟地址与物理地址之间通过页表来映射，映射通过 MMU （内存管理单元）实现。

![](../image/内存分页示意图.webp)

当进程访问的虚拟地址在页表中查找不到时，会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，然后返回用户空间恢复进程运行。

因为页的大小是固定的，因此页与页之间是紧密排列的，不会有外部碎片。

> 上面这句话太粗略了。

但是页也有新的问题，即会引入内部内存碎片。因为分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少也会分配一个页。页内会多出程序用不到的一些内存。

如果内存空间不够，则操作系统会将其他正在运行的进程中**最久未被使用的**的内存页释放掉，并将数据**换出**（Swap Out）到硬盘。如果后面又需要用到，再将其**换入**（Swap In）到硬盘。此时与硬盘交换的数据会有几个页或者几十个页，相比分段机制效率会高很多。

分页机制使得程序不需要一次性将程序全部加载到物理内存中，而是进行内存映射后，只将最近程序执行到的指令或数据加载到物理内存。
### 映射方式

分页机制下，虚拟地址分为两部分：页号和页内偏移。

页号作为页表索引，页表包含物理页每页所在物理内存的**基地址**，这个地址和页内偏移组合就形成了物理内存地址。

![](../image/内存分页寻址逻辑.webp)

上面这种是最简单的分页逻辑，这种方式的页表会非常庞大。

因为**页表必须映射全部虚拟地址空间**，因此如果每页只有 4KB，在 32 位环境下，虚拟内存有 4GB，需要大约 100万 个页，即一共有 100万 个页表项。另外由于每个进程都有自己的虚拟地址空间，即有自己的页表，假如有 100 个进程，则还要再乘以 100。更别说 64 位系统了。
### 多级页表

为了提升存储效率，一般会采用多级页表（Multi-Level Page Table）的解决方案。

以二级页表为例。一级页表中存储**一级页号**和**二级页表地址**，二级页表则在一级页表项的基础上继续划分，存储**二级页号**和**对应的物理页的物理基地址**。

![](../image/内存二级页表寻址逻辑.webp)

多级页表看上去需要更多的空间，但是实际上，顶级页表能够覆盖整个虚拟地址空间，所有次级页表只在需要的时候创建即可。

> 由于局部性原理（将频繁访问的数据放到更高性能的存储设备上），实际运行时，进程使用的虚拟地址空间大部分页表项是空的，对于已分配的页表项，如果物理内存紧张，也会将最近最久未访问的页换出到硬盘。

假如一级页表有 1024 个二级页表（一级页号和二级页表项），二级页表包含 1024 个页表项（二级页号和物理页基地址）。此时一级页表已经能覆盖全部的虚拟地址空间，只不过划分的间隔更大而已。

对于 64 位系统来说，通常采用四级页表，分别为：
- 全局页目录项（Page Global Directory，PGD）。
- 上层页目录项（Page Upper Directory，PUD）。
- 中间页目录项（Page Middle Directory，PMD）。
- 页表项（Page Table Entry，PTE）。

因此一个虚拟地址被划分为五部分，除了上面四个页表的页号外，还有页内偏移。

![](../image/内存多级页表示意图.webp)
### TLB

多级页表解决了空间上的问题，但是计算物理地址又多了几层转换工序，降低了地址转换的速度。为了解决效率问题，并且借助局部性原理，现在的 CPU 芯片中加入了一个专门存放程序最常访问的页表项的 Cache，即 TLB（Translation Lookaside Buffer），通常称为页表缓存、转址旁路缓存、快表等。

有了 TLB，MMU 会优先从 TLB 寻址，如果没找到，才会继续按照常规流程查表。TLB 的命中率是很高的，大大加快寻址效率。